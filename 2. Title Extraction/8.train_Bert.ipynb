{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_Bert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"11P6AGaGTr7LoEWhudAUvd_lcRfNl0mJR","authorship_tag":"ABX9TyNvGHShxO5JVYSWe0JsbNtm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"l3Jz_FEn9PbH","colab_type":"code","colab":{}},"source":["!pip install sentencepiece\n","!git clone https://github.com/google-research/bert"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nV5U1dEGoQK-","colab_type":"text"},"source":["flags 오류나면 from absl import flags 하고\n","\n","flags = tf.flags 주석처리"]},{"cell_type":"code","metadata":{"id":"2snlZWC9iELY","colab_type":"code","colab":{}},"source":["%cd bert"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BK25DAjmiMAG","colab_type":"code","colab":{}},"source":["!tf_upgrade_v2 --infile optimization.py --outfile optimization.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENTJR3Krjqna","colab_type":"code","colab":{}},"source":["!tf_upgrade_v2 --infile run_pretraining.py --outfile run_pretraining.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-RoMepqj4Ax","colab_type":"code","colab":{}},"source":["%cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PecNlDR5qE-","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loP48LNN9eec","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import json\n","import nltk\n","import random\n","import logging\n","import tensorflow as tf\n","import sentencepiece as spm\n","\n","from glob import glob\n","from google.colab import auth, drive\n","from tensorflow.keras.utils import Progbar\n","\n","sys.path.append(\"bert\")\n","\n","from bert import modeling, optimization, tokenization\n","from bert.run_pretraining import input_fn_builder, model_fn_builder\n","\n","auth.authenticate_user()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8pm8dlMXBdQu","colab_type":"code","colab":{}},"source":["# configure logging\n","log = logging.getLogger('tensorflow')\n","log.setLevel(logging.INFO)\n","\n","# create formatter and add it to the handlers\n","formatter = logging.Formatter('%(asctime)s :  %(message)s')\n","sh = logging.StreamHandler()\n","sh.setLevel(logging.INFO)\n","sh.setFormatter(formatter)\n","log.handlers = [sh]\n","\n","if 'COLAB_TPU_ADDR' in os.environ:\n","  log.info(\"Using TPU runtime\")\n","  USE_TPU = True\n","  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","\n","  with tf.Session(TPU_ADDRESS) as session:\n","    log.info('TPU address is ' + TPU_ADDRESS)\n","    # Upload credentials to TPU.\n","    with open('/content/adc.json', 'r') as f:\n","      auth_info = json.load(f)\n","    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","    \n","else:\n","  log.warning('Not connected to TPU runtime')\n","  USE_TPU = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mi2x1RB7Bpjw","colab_type":"code","colab":{}},"source":["AVAILABLE =  {'af','ar','bg','bn','br','bs','ca','cs',\n","              'da','de','el','en','eo','es','et','eu',\n","              'fa','fi','fr','gl','he','hi','hr','hu',\n","              'hy','id','is','it','ja','ka','kk','ko',\n","              'lt','lv','mk','ml','ms','nl','no','pl',\n","              'pt','pt_br','ro','ru','si','sk','sl','sq',\n","              'sr','sv','ta','te','th','tl','tr','uk',\n","              'ur','vi','ze_en','ze_zh','zh','zh_cn',\n","              'zh_en','zh_tw','zh_zh'}\n","\n","LANG_CODE = \"ko\" #@param {type:\"string\"}\n","\n","assert LANG_CODE in AVAILABLE, \"Invalid language code selected\"\n","\n","!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.'$LANG_CODE'.gz -O dataset.txt.gz\n","!gzip -d dataset.txt.gz\n","!tail dataset.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9YmBRi5kB0R_","colab_type":"code","colab":{}},"source":["# DEMO_MODE = True #@param {type:\"boolean\"}\n","\n","# if DEMO_MODE:\n","#   CORPUS_SIZE = 1000000\n","# else:\n","#   CORPUS_SIZE = 100000000 #@param {type: \"integer\"}\n","  \n","# !(head -n $CORPUS_SIZE dataset.txt) > subdataset.txt\n","# !mv subdataset.txt dataset.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUvZNiHXB7hd","colab_type":"code","colab":{}},"source":["regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n","\n","def normalize_text(text):\n","  # lowercase text\n","  text = str(text).lower()\n","  # remove non-UTF\n","  text = text.encode(\"utf-8\", \"ignore\").decode()\n","  # remove punktuation symbols\n","  text = \" \".join(regex_tokenizer.tokenize(text))\n","  return text\n","\n","def count_lines(filename):\n","  count = 0\n","  with open(filename) as fi:\n","    for line in fi:\n","      count += 1\n","  return count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epRqw4vjB-e_","colab_type":"code","colab":{}},"source":["RAW_DATA_FPATH = \"dataset.txt\" #@param {type: \"string\"}\n","PRC_DATA_FPATH = \"proc_dataset.txt\" #@param {type: \"string\"}\n","\n","# apply normalization to the dataset\n","# this will take a minute or two\n","\n","total_lines = count_lines(RAW_DATA_FPATH)\n","bar = Progbar(total_lines)\n","\n","with open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n","  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n","    for l in fi:\n","      fo.write(normalize_text(l)+\"\\n\")\n","      bar.add(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgTbf-gkCCUc","colab_type":"code","colab":{}},"source":["MODEL_PREFIX = \"tokenizer\" #@param {type: \"string\"}\n","VOC_SIZE = 32000 #@param {type:\"integer\"}\n","SUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\n","NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n","\n","SPM_COMMAND = ('--input={} --model_prefix={} '\n","               '--vocab_size={} --input_sentence_size={} '\n","               '--shuffle_input_sentence=true ' \n","               '--bos_id=-1 --eos_id=-1').format(\n","               PRC_DATA_FPATH, MODEL_PREFIX, \n","               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n","\n","spm.SentencePieceTrainer.Train(SPM_COMMAND)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJmUGL-7CE_W","colab_type":"code","colab":{}},"source":["def read_sentencepiece_vocab(filepath):\n","  voc = []\n","  with open(filepath, encoding='utf-8') as fi:\n","    for line in fi:\n","      voc.append(line.split(\"\\t\")[0])\n","  # skip the first <unk> token\n","  voc = voc[1:]\n","  return voc\n","\n","snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n","print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n","print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1zIDcoVCHZt","colab_type":"code","colab":{}},"source":["def parse_sentencepiece_token(token):\n","    if token.startswith(\"▁\"):\n","        return token[1:]\n","    else:\n","        return \"##\" + token\n","\n","bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n","ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n","bert_vocab = ctrl_symbols + bert_vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QOMyU_MCJ1M","colab_type":"code","colab":{}},"source":["bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n","print(len(bert_vocab))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUbcSFWn9nyk","colab_type":"code","colab":{}},"source":["VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n","\n","with open(VOC_FNAME, \"w\") as fo:\n","  for token in bert_vocab:\n","    fo.write(token+\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLhbc8Z19oWG","colab_type":"code","colab":{}},"source":["!mkdir ./shards\n","!split -a 4 -l 256000 -d $PRC_DATA_FPATH ./shards/shard_\n","!ls ./shards/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DjZ-4Pk89xSB","colab_type":"text"},"source":["MAX_SEQ_LENGTH: BERT의 모델 입력의 최장 토큰 길이\n","\n","\n","MASKED_LM_PROB: BERT의 학습 중 Masked LM의 비율을 조정한다.\n","\n","MAX_PREDICTIONS: Sequence별 예측할 최대 길이\n","\n","DO_LOWER_CASE: 영문자를 lower(소문자화) 할 지. 한글에는 의미없다.\n","\n","PROCESSES: 전처리할때 CPU 몇개 쓸지\n","\n","PRETRAINING_DIR: 프리트레인 데이터 폴더 이름"]},{"cell_type":"code","metadata":{"id":"Mxzc_ib79oec","colab_type":"code","colab":{}},"source":["MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n","MASKED_LM_PROB = 0.15 #@param\n","MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n","DO_LOWER_CASE = True #@param {type:\"boolean\"}\n","PROCESSES = 4 #@param {type:\"integer\"}\n","PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w__EElqJeloi","colab_type":"code","colab":{}},"source":["%cd bert"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"teiRK5SQLztK","colab_type":"code","colab":{}},"source":["!tf_upgrade_v2 --infile create_pretraining_data.py --outfile create_pretraining_data.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xgk0Iumyn2kF","colab_type":"code","colab":{}},"source":["!tf_upgrade_v2 --infile tokenization.py --outfile tokenization.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ARpXviggkO-","colab_type":"code","colab":{}},"source":["%cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPQMf92w9oiP","colab_type":"code","colab":{}},"source":["XARGS_CMD = (\"ls ./shards/ | \"\n","             \"xargs -n 1 -P {} -I{} \"\n","             \"python3 bert/create_pretraining_data.py \"\n","             \"--input_file=./shards/{} \"\n","             \"--output_file={}/{}.tfrecord \"\n","             \"--vocab_file={} \"\n","             \"--do_lower_case={} \"\n","             \"--max_predictions_per_seq={} \"\n","             \"--max_seq_length={} \"\n","             \"--masked_lm_prob={} \"\n","             \"--random_seed=34 \"\n","             \"--dupe_factor=5\")\n","\n","XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n","                             VOC_FNAME, DO_LOWER_CASE, \n","                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)\n","\n","tf.io.gfile.makedirs(PRETRAINING_DIR)\n","!$XARGS_CMD"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGJpjntq-SZL","colab_type":"code","colab":{}},"source":["BUCKET_NAME = \"jun_bucket_storage\" #@param {type:\"string\"}\n","MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n","tf.io.gfile.makedirs(MODEL_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XK0P9_gf-YSP","colab_type":"code","colab":{}},"source":["bert_base_config = {\n","  \"attention_probs_dropout_prob\": 0.1, \n","  \"directionality\": \"bidi\", \n","  \"hidden_act\": \"gelu\", \n","  \"hidden_dropout_prob\": 0.1, \n","  \"hidden_size\": 768, \n","  \"initializer_range\": 0.02, \n","  \"intermediate_size\": 3072, \n","  \"max_position_embeddings\": 512, \n","  \"num_attention_heads\": 12, \n","  \"num_hidden_layers\": 12, \n","  \"pooler_fc_size\": 768, \n","  \"pooler_num_attention_heads\": 12, \n","  \"pooler_num_fc_layers\": 3, \n","  \"pooler_size_per_head\": 128, \n","  \"pooler_type\": \"first_token_transform\", \n","  \"type_vocab_size\": 2, \n","  \"vocab_size\": VOC_SIZE\n","}\n","\n","with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n","  json.dump(bert_base_config, fo, indent=2)\n","  \n","with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n","  for token in bert_vocab:\n","    fo.write(token+\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxMifovY-a84","colab_type":"code","colab":{}},"source":["if BUCKET_NAME:\n","  !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fSDyQEkyovK","colab_type":"code","colab":{}},"source":["%cd bert"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZCSx8eqywc2","colab_type":"code","colab":{}},"source":["!tf_upgrade_v2 --infile modeling.py --outfile modeling.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBYov6yMzCSc","colab_type":"code","colab":{}},"source":["%cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxrGQScU-gYf","colab_type":"code","colab":{}},"source":["BUCKET_NAME = \"beomi-blog-sample\" #@param {type:\"string\"}\n","MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n","PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}\n","VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n","\n","# Input data pipeline config\n","TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n","MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n","MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n","MASKED_LM_PROB = 0.15 #@param\n","\n","# Training procedure config\n","EVAL_BATCH_SIZE = 64\n","LEARNING_RATE = 2e-5\n","TRAIN_STEPS = 1000000 #@param {type:\"integer\"}\n","SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n","NUM_TPU_CORES = 8\n","\n","if BUCKET_NAME:\n","  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n","else:\n","  BUCKET_PATH = \".\"\n","\n","BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n","DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n","\n","VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n","CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n","\n","INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n","\n","bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n","input_files = tf.io.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n","\n","log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n","log.info(\"Using {} data shards\".format(len(input_files)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G04PfJiR-kFx","colab_type":"code","colab":{}},"source":["model_fn = model_fn_builder(\n","      bert_config=bert_config,\n","      init_checkpoint=INIT_CHECKPOINT,\n","      learning_rate=LEARNING_RATE,\n","      num_train_steps=TRAIN_STEPS,\n","      num_warmup_steps=10,\n","      use_tpu=USE_TPU,\n","      use_one_hot_embeddings=True)\n","\n","tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","\n","run_config = tf.contrib.tpu.RunConfig(\n","    cluster=tpu_cluster_resolver,\n","    model_dir=BERT_GCS_DIR,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n","    tpu_config=tf.contrib.tpu.TPUConfig(\n","        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n","        num_shards=NUM_TPU_CORES,\n","        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n","\n","estimator = tf.contrib.tpu.TPUEstimator(\n","    use_tpu=USE_TPU,\n","    model_fn=model_fn,\n","    config=run_config,\n","    train_batch_size=TRAIN_BATCH_SIZE,\n","    eval_batch_size=EVAL_BATCH_SIZE)\n","  \n","train_input_fn = input_fn_builder(\n","        input_files=input_files,\n","        max_seq_length=MAX_SEQ_LENGTH,\n","        max_predictions_per_seq=MAX_PREDICTIONS,\n","        is_training=True)\n","\n","# 학습하자!!\n","estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"],"execution_count":null,"outputs":[]}]}