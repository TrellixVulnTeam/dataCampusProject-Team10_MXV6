{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonkim313/dataCampusProject-Team10/blob/master/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnemJTAf16LY",
        "colab_type": "text"
      },
      "source": [
        "!git clone https://github.com/yoonkim313/dataCampusProject-Team10.git\n",
        "\n",
        "    ! python3 /content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/ocr/deep-text-recognition/train.py\n",
        "    ! python /content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/main.ipynb\n",
        "    sys.path.insert(0,nb_path)\n",
        "    !pip install --target=$nb_path transformers\n",
        "    !apt-get update\n",
        "    !apt-get g++ openjdk-8-jdk \n",
        "    !pip3 install --target=$nb_path konlpy\n",
        "    !pip install --target=$nb_path soykeyword\n",
        "    !pip install --target=$nb_path krwordrank\n",
        "    !pip install --target=$nb_path heapq\n",
        "    !pip install --target=$nb_path kss\n",
        "    !pip install --target=$nb_path bert\n",
        "    !pip install --target=$nb_path textrankr\n",
        "    !pip install --target=$nb_path lexrankr\n",
        "    %cd /content/drive/Shared drives/BigDATA TEAM 10/py-hanspell\n",
        "    !python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-9nVAJZfAnm",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0593f00f-744a-4350-ccfd-8075aeeb6c03"
      },
      "source": [
        "#@title A-Catcher 실행 환경 구축\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shared drives/BigDATA TEAM 10\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from konlpy.tag import Hannanum, Okt, Komoran\n",
        "h = Hannanum()\n",
        "o = Okt()\n",
        "k = Komoran\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import heapq\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "from collections import deque, defaultdict\n",
        "from ast import literal_eval\n",
        "from collections import defaultdict\n",
        "from pprint import pprint\n",
        "from krwordrank.word import KRWordRank\n",
        "from copy import deepcopy\n",
        "import kss\n",
        "import itertools\n",
        "import unicodedata\n",
        "import requests\n",
        "from functools import reduce\n",
        "import torch\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from textrankr import TextRank\n",
        "from lexrankr import LexRank\n",
        "from hanspell import spell_checker  \n",
        "\n",
        "!pip install --upgrade google-cloud-vision\n",
        "!apt-get install -y poppler-utils\n",
        "\n",
        "%cd /content/drive/'Shared drives'/'BigDATA TEAM 10'\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "from flask_admin.contrib.fileadmin import FileAdmin\n",
        "from flask_admin import Admin\n",
        "from flask_dropzone import Dropzone\n",
        "from pdf2image import convert_from_path\n",
        "import io\n",
        "import os\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "import logging\n",
        "from pptx import Presentation\n",
        "from pptx_tools import utils\n",
        "\n",
        "%cd /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\n",
        "!pip install transformers\n",
        "import frame_parser\n",
        "path=\"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\"\n",
        "parser = frame_parser.FrameParser(model_path=path, language='ko')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shared drives/BigDATA TEAM 10\n",
            "Collecting google-cloud-vision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/7f/e10d602c2dc3f749f1b78377a3357790f1da71b28e7da9e5bc20b3a9bd40/google_cloud_vision-1.0.0-py2.py3-none-any.whl (435kB)\n",
            "\u001b[K     |████████████████████████████████| 440kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-vision) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.52.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (0.4.8)\n",
            "Installing collected packages: google-cloud-vision\n",
            "Successfully installed google-cloud-vision-1.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 154 kB of archives.\n",
            "After this operation, 613 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.10 [154 kB]\n",
            "Fetched 154 kB in 0s (2,017 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 144599 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.62.0-2ubuntu2.10_amd64.deb ...\n",
            "Unpacking poppler-utils (0.62.0-2ubuntu2.10) ...\n",
            "Setting up poppler-utils (0.62.0-2ubuntu2.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/drive/Shared drives/BigDATA TEAM 10\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=3bb1711de4d9b33a689319543115033c44609e76ec62604fe4457a5d18ce4ed8\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n",
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\n",
            "...model is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNYsHPbjTTv1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title 자연어 처리 모듈\n",
        "class Text():\n",
        "    def __init__(self, text):\n",
        "        text = re.sub(\"'\", ' ', text)\n",
        "        paragraphs = text.split('\\n')\n",
        "        self.text = text\n",
        "        self.paragraphs = [i for i in paragraphs if i]\n",
        "        self.counts = len(self.paragraphs)\n",
        "        self.docs = [kss.split_sentences(paragraph) for paragraph in paragraphs if kss.split_sentences(paragraph)]\n",
        "        self.newtext = deepcopy(self.text)\n",
        "        print(\"TEXT\")\n",
        "\n",
        "    def findall(self, p, s):\n",
        "        i = s.find(p)\n",
        "        while i != -1:\n",
        "            yield i\n",
        "            i = s.find(p, i + 1)\n",
        "      \n",
        "    def countMatcher(self, sentences, paragraph_no):\n",
        "        paragraph = self.docs[paragraph_no]\n",
        "        total_no = len(paragraph)\n",
        "        vec = [0] * total_no\n",
        "        \n",
        "        for idx, candidate in enumerate(paragraph):\n",
        "            for sentence in sentences:\n",
        "                if sentence[:4] in candidate:\n",
        "                    vec[idx] += 1\n",
        "        print(\"Vec \",vec)\n",
        "        return vec\n",
        "\n",
        "class Highlight(Text):\n",
        "    def __init__(self, text):\n",
        "        super().__init__(text)\n",
        "        print(\"Highlight\")\n",
        "        okt = Okt()\n",
        "        h = Hannanum()\n",
        "\n",
        "        wordrank_extractor = KRWordRank(min_count=3, max_length=10)\n",
        "        print(\"paragraph \",self.paragraphs)\n",
        "        self.keywords, rank, graph = wordrank_extractor.extract(self.paragraphs)\n",
        "        self.path = \"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\"\n",
        "        p = []\n",
        "        kw = []\n",
        "        for k, v in self.keywords.items():\n",
        "            p.append(okt.pos(k))\n",
        "            kw.append(k)\n",
        "        words = self.text.split(' ')\n",
        "        s = set()\n",
        "        keylist = [word for i in kw for word in words if i in word]\n",
        "        keylist = [i for i in keylist if len(i)>2]\n",
        "        for i in keylist:\n",
        "            if len(i)>2:\n",
        "              s.add(i)\n",
        "        print(\"KEYLIST: \",keylist)\n",
        "        p = [okt.pos(word) for word in s]\n",
        "        s = set()\n",
        "        for idx in range(len(p)):\n",
        "            ls = p[idx]\n",
        "            for j in range(len(ls)):\n",
        "                tag = ls[j][1]\n",
        "                word = ls[j][0]\n",
        "                if tag == \"Noun\":\n",
        "                    s.add(word)\n",
        "        self.keys = []\n",
        "        for temp in s:\n",
        "            self.keys.append(\" \" + temp)\n",
        "\n",
        "    \n",
        "    def add_tags_keywords(self):\n",
        "        self.candidates = self.keys\n",
        "        self.newtext = deepcopy(self.text)\n",
        "        self.idx = [(i, i + len(candidate)) for candidate in self.candidates for i in\n",
        "                        self.findall(candidate, self.text)]\n",
        "        for i in range(len(self.idx)):\n",
        "            try:\n",
        "                self.idx = [(start, start + len(candidate)) for candidate in self.candidates for start in\n",
        "                            self.findall(candidate, self.newtext)]\n",
        "                word = self.newtext[self.idx[i][0]:self.idx[i][1]]\n",
        "                tagged = \" <mark style='background-color:#FFD0F2'>%s</mark>\" % (word)\n",
        "                self.newtext = tagged.join([self.newtext[:self.idx[i][0]], self.newtext[self.idx[i][1]:]])\n",
        "            except:\n",
        "                pass\n",
        "        return self.newtext\n",
        "\n",
        "\n",
        "    def add_tags_conj(self, txt):\n",
        "        conj = '그리고, 그런데, 그러나, 그래도, 그래서, 또는, 및, 즉, 게다가, 따라서, 때문에, 아니면, 왜냐하면, 단, 오히려, 비록, 예를 들어, 반면에, 하지만, 그렇다면, 바로, 이에 대해'\n",
        "        conj = conj.replace(\"'\", \"\")\n",
        "        self.candidates = conj.split(\",\")\n",
        "        self.newtext = deepcopy(txt)\n",
        "        self.idx = [(i, i + len(candidate)) for candidate in self.candidates for i in\n",
        "                        self.findall(candidate, txt)]\n",
        "        for i in range(len(self.idx)):\n",
        "            try:\n",
        "                self.idx = [(start, start + len(candidate)) for candidate in self.candidates for start in\n",
        "                            self.findall(candidate, self.newtext)]\n",
        "                word = self.newtext[self.idx[i][0]:self.idx[i][1]]\n",
        "                res = \"\"\n",
        "                tagged = \" <mark style='background-color:#F9D877'>%s</mark>\" % (word)\n",
        "                print(tagged)\n",
        "                self.newtext = tagged.join([self.newtext[:self.idx[i][0]], self.newtext[self.idx[i][1]:]])\n",
        "            except:\n",
        "                pass\n",
        "        return self.newtext\n",
        "\n",
        "    def highlight(self):\n",
        "          result = self.add_tags_keywords()\n",
        "          cleanr = re.compile(\"</mark>.{0,5}<mark style='background-color:#FFD0F2'>\")\n",
        "          patterns = re.findall(\"</mark>.{0,5}<mark style='background-color:#FFD0F2'>\",result)\n",
        "          w = [i[7:-39] for i in patterns]\n",
        "          for i in range(len(w)):\n",
        "            result = re.sub(patterns[i], w[i], result)\n",
        "          txt = self.add_tags_conj(result)\n",
        "          print(\"Highlighted Result \", txt)\n",
        "          return txt\n",
        "class Node:\n",
        "    def __init__(self, data):\n",
        "        self.words = data[0]\n",
        "        self.usage = data[1]\n",
        "        self.tags = data[3]\n",
        "        self.next = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str((self.words, self.tags))\n",
        "\n",
        "\n",
        "class LinkedList:\n",
        "  def __init__(self):\n",
        "      self.head = None\n",
        "\n",
        "  def __repr__(self):\n",
        "      node = self.head\n",
        "      nodes = []\n",
        "      while node is not None:\n",
        "          nodes.append(str(node.tags))\n",
        "          node = node.next\n",
        "      nodes.append(\"None\")\n",
        "      return ' -> '.join(nodes)\n",
        "\n",
        "\n",
        "class Relation(object):\n",
        "  def __init__(self):\n",
        "      self.path=\"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\"\n",
        "      self.parser = parser\n",
        "\n",
        "  def findConsecutiveBIO(self, words, tag):\n",
        "      began = False\n",
        "      count = 1\n",
        "      que = \" \"\n",
        "      temp_word = []\n",
        "      temp_tag = []\n",
        "      res = \" \"\n",
        "\n",
        "      for i in range(len(words)):\n",
        "          if not tag[i].startswith(\"O\"):\n",
        "              began = True\n",
        "              temp_word.append(words[i])\n",
        "              temp_tag.append(tag[i].split(\"-\")[1])\n",
        "          elif tag[i].startswith(\"O\"):\n",
        "              began = False\n",
        "      r = que.join(temp_word)\n",
        "      s = que.join(temp_tag)\n",
        "      return r, s\n",
        "\n",
        "  def relationPopup(self, sent):\n",
        "      parsed = parser.parser(sent, sent_id='1', result_format='conll')\n",
        "      parsedList = LinkedList()\n",
        "      self.final = dict()\n",
        "      for j in range(len(parsed)):\n",
        "          parsed_candidate = parsed[j]\n",
        "          print(\" Parsed Candidate \", parsed_candidate)\n",
        "          new_node = Node(parsed_candidate)\n",
        "          if j == 0:\n",
        "              old_node = new_node\n",
        "              parsedList.head = old_node\n",
        "          elif j == len(parsed) - 1:\n",
        "              old_node.next = new_node\n",
        "              new_node.next = None\n",
        "              print(j, '  ', parsedList)\n",
        "              self.final[j] = parsedList\n",
        "          else:\n",
        "              old_node.next = new_node\n",
        "              old_node = new_node\n",
        "      res = dict()\n",
        "\n",
        "      for k, v in self.final.items():\n",
        "          a = v.head\n",
        "          while a is not None:\n",
        "              i = 0\n",
        "              temp = \" \"\n",
        "              if len(a.words) == len(a.tags):\n",
        "                  w, t= self.findConsecutiveBIO(a.words, a.tags)\n",
        "                  res[t]=w\n",
        "              else:\n",
        "\n",
        "                  print(\"ERROR OCCURED\")\n",
        "              a = a.next\n",
        "\n",
        "      return res\n",
        "      \n",
        "  def arrow(self, words, tags):\n",
        "      d = defaultdict(set)\n",
        "      words = words.split(\" \")\n",
        "      tags = tags.split(\" \")\n",
        "      total = ''\n",
        "      tag = ''\n",
        "      for idx, relation in enumerate(tags):\n",
        "        print(relation)\n",
        "        d[relation].add(idx)\n",
        "      res = \"\"\n",
        "      for i, s in d.items():\n",
        "        print(s)\n",
        "        temp = []\n",
        "        for idx in s:\n",
        "          w = okt.pos(words[idx])\n",
        "          print(\"word\",w)\n",
        "          if  w == \"Noun\" or w == \"Adjective\":\n",
        "            temp.append(words[idx])\n",
        "        total += ' '.join(temp)\n",
        "        total += \"➜\"\n",
        "        tag += i\n",
        "        tag += \"➜\"\n",
        "      return total[:-1], tag[:-1]\n",
        "\n",
        "class Summarize(Highlight):\n",
        "    def __init__(self, text, paragraph_no):\n",
        "      super().__init__(text)\n",
        "      print(\"length of paragraphs \",len(self.paragraphs))\n",
        "      self.txt = self.paragraphs[paragraph_no]\n",
        "      self.paragraph_no = paragraph_no\n",
        "\n",
        "    def summarize(self):\n",
        "        url = \"https://api.smrzr.io/summarize?ratio=0.15\"\n",
        "        headers = {\n",
        "            'content-type': 'raw/text',\n",
        "            'origin': 'https://smrzr.io',\n",
        "            'referer': 'https://smrzr.io/',\n",
        "            'sec-fetch-dest': 'empty',\n",
        "            'sec-fetch-mode': 'cors',\n",
        "            'sec-fetch-site': 'same-site',\n",
        "            \"user-agent\": \"Mozilla/5.0\"\n",
        "        }\n",
        "        resp = requests.post(url, headers=headers, data= self.txt.encode('utf-8'))\n",
        "        assert resp.status_code == 200\n",
        "        summary = resp.json()['summary']\n",
        "        temp = summary.split('\\n')\n",
        "        print(\"BERT: \", temp)\n",
        "        return temp\n",
        "\n",
        "\n",
        "    def summarizeTextRank(self, max=1):\n",
        "        tr = TextRank(self.txt)\n",
        "        \n",
        "        summary = tr.summarize(max).split('\\n')\n",
        "        print(\"Textrank: \",summary)\n",
        "        return summary\n",
        "\n",
        "\n",
        "    def summarizeLexRank(self):\n",
        "        lr = LexRank()\n",
        "        lr.summarize(self.txt)\n",
        "        summaries = lr.probe()\n",
        "        print(\"Lexrank: \",summaries)\n",
        "        return summaries\n",
        "\n",
        "    def ensembleSummarize(self):\n",
        "        a = np.array(self.countMatcher(self.summarize(), self.paragraph_no))\n",
        "        \n",
        "        try:\n",
        "          b = np.array(self.countMatcher(self.summarizeLexRank(), self.paragraph_no))\n",
        "        except:\n",
        "          b = np.zeros_like(a)\n",
        "        c = np.array(self.countMatcher(self.summarizeTextRank(),self.paragraph_no))\n",
        "        result= a+b+c\n",
        "        i, = np.where(result == max(result))\n",
        "        txt, index = self.docs[self.paragraph_no][i[0]], i[0]\n",
        "        return txt, index\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/ocr/My Project-a3f9a30ceabf.json\"\n",
        "client = vision.ImageAnnotatorClient()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUaRsVQ8CPxn",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc6554fd-83e5-42c5-d3d0-b54f16660a10"
      },
      "source": [
        "#@title Flask 작동 코드\n",
        "%cd /content/drive/'Shared drives'/'BigDATA TEAM 10'/dataCampusProject-Team10/flask\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "basedir = '/content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/flask' \n",
        "upload_dir = os.path.join(basedir, 'uploads')  # basedir 의 uploads 에 파일 저장\n",
        "#################################################################################################################\n",
        "\n",
        "admin = Admin(name='Uploaded Files')\n",
        "admin.init_app(app)\n",
        "dropzone = Dropzone(app)\n",
        "admin.add_view(FileAdmin(upload_dir, name='FILES')) \n",
        "app.config['DROPZONE_ALLOWED_FILE_CUSTOM'] = True\n",
        "app.config['DROPZONE_ALLOWED_FILE_TYPE'] = 'image/*, .pdf, .txt'\n",
        "app.config['DROPZONE_REDIRECT_VIEW']='result'\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "@app.route(\"/\", methods=['GET', 'POST'])\n",
        "def upload(num=None):\n",
        "    if request.method == 'POST':\n",
        "        f = request.files.get('file')\n",
        "        f.save(os.path.join(upload_dir, f.filename))\n",
        "        images = convert_from_path(os.path.join(upload_dir, f.filename))\n",
        "        for i, image in enumerate(images):\n",
        "            fname = \"uploads/image\" + str(i) + \".jpg\"\n",
        "            image.save(fname, \"JPEG\")\n",
        "        # return redirect(url_for('result'))\n",
        "    return render_template('homepage.html',num=num)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "@app.route(\"/result\", methods=['GET', 'POST'])\n",
        "def result(num=None):\n",
        "    # if request.method == 'POST':\n",
        "    with io.open(\"/content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/flask/uploads/image0.jpg\",\n",
        "                  'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.types.Image(content=content)\n",
        "    response = client.text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    box = 0, 0, 0, 0, 0, 0, 0, 0\n",
        "    pre_box = 0, 0, 0, 0, 0, 0, 0, 0\n",
        "    result_text = []\n",
        "    a = ' '\n",
        "    for text in texts[1:]:\n",
        "        for vertex in text.bounding_poly.vertices:\n",
        "            vertices = (['{},{}'.format(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices])\n",
        "            x1, x2, x3, x4 = vertices[0].split(',')[0], vertices[1].split(',')[0], vertices[2].split(',')[0], \\\n",
        "                              vertices[3].split(',')[0]\n",
        "            y1, y2, y3, y4 = vertices[0].split(',')[1], vertices[1].split(',')[1], vertices[2].split(',')[1], \\\n",
        "                              vertices[3].split(',')[1]\n",
        "            break\n",
        "\n",
        "        box = int(x1), int(y1), int(x2), int(y2), int(x3), int(y3), int(x4), int(y4)\n",
        "\n",
        "        if (box[1] - pre_box[5]) >= 30:\n",
        "            result_text.append(a)\n",
        "            a = text.description\n",
        "        else:\n",
        "            a += text.description + ' '\n",
        "        pre_box = box\n",
        "    result_text.append(a)\n",
        "    print(\" 🧚‍♀️ OCR running 🧚‍♀️ \")\n",
        "    \n",
        "    b = \"\\n\"\n",
        "    b = b.join(result_text)\n",
        "    with open(\"/content/result_text.txt\", 'w') as f:\n",
        "      f.write(b)\n",
        "    \n",
        "    txt = \"\"\n",
        "\n",
        "    with open(\"/content/result_text.txt\") as f:\n",
        "      while True:\n",
        "        line = f.readline()\n",
        "        line = spell_checker.check(line)[2]\n",
        "        print(\"Checked spelling \",line)\n",
        "        txt += line\n",
        "        txt += \"\\n\"\n",
        "        if not line: \n",
        "          break\n",
        "        \n",
        "    txt = [i.replace(\"딸\", \"말\") for i in txt.split(\"\\n\") if i]\n",
        "\n",
        "\n",
        "    print(\" 😍  NLP running  😍 \")\n",
        "    d = [kss.split_sentences(i) for i in txt if i]\n",
        "    rel = Relation()\n",
        "    pu = []\n",
        "    for paragraph in range(len(d)):\n",
        "        a = []\n",
        "        for i in range(len(d[paragraph])):\n",
        "            a.append(rel.relationPopup(d[paragraph][i]))\n",
        "        pu.append(a)\n",
        "\n",
        "    pop_doc=[]\n",
        "    for p in range(len(pu)):\n",
        "        dct = [\"\"]*len(pu[p])\n",
        "        for s in range(len(pu[p])):\n",
        "            counter = 0\n",
        "            for k, v in pu[p][s].items():\n",
        "                z = k.split(\" \")\n",
        "                if len(Counter(z))>counter and 8>len(Counter(z))>1:\n",
        "                    dct[s]=(str(v)+\":\"+str(k))\n",
        "                counter = len(Counter(z))\n",
        "        pop_doc.append(dct)\n",
        "    print(\"Relation Extracted\")\n",
        "    rs = \"\"\n",
        "    for p in range(len(pop_doc)):\n",
        "        pop = [i for i in pop_doc[p] if i]\n",
        "        for r in pop:\n",
        "            temp = r.split(\":\")\n",
        "            s = \"\"\n",
        "            sent = \"\"\n",
        "            tagged = temp[1].split(\" \")\n",
        "            words = temp[0].split(\" \")\n",
        "            curr = tagged[0]\n",
        "            print(tagged, words, curr)\n",
        "            for i, tag in enumerate(tagged):\n",
        "                if curr not in tag:\n",
        "                      s+=\"▶ \"\n",
        "                      sent+=\"▶ \"\n",
        "                s+=(\" \"+tag)\n",
        "                sent+=(\" \"+words[i])\n",
        "                curr = tag\n",
        "            rs += \"<a data-toggle='tooltip' data-placement='top' title=\"+ str(s) + \">\" + str(sent) +\"</a>\"+\"<br>\"\n",
        "        rs+='<\\n\\n>'\n",
        "    with open(\"/content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/flask/relation.txt\",'w') as file:\n",
        "        file.write(rs)\n",
        "\n",
        "\n",
        "    result = '\\n'.join(txt)\n",
        "    high = Highlight(result)\n",
        "    tagged = high.highlight()\n",
        "    paragraphs = [i for i in tagged.split('\\n') if i]\n",
        "    total = ''\n",
        "    for idx in range(len(paragraphs)):\n",
        "      \n",
        "      summarizer = Summarize(result, idx)\n",
        "      txt, id = summarizer.ensembleSummarize()\n",
        "      print(\"summarized \",txt)\n",
        "      paragraph = kss.split_sentences(paragraphs[idx])\n",
        "      sent_counts = len(paragraph)\n",
        "      for sent in range(sent_counts):\n",
        "        if txt[:3] in paragraph[sent]:\n",
        "          relation = \"\"\n",
        "          string =\"<u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'>\" + paragraph[sent] +\"</u>\"\n",
        "          total += string\n",
        "        else:\n",
        "          total += paragraph[sent]\n",
        "      if idx is not len(paragraphs)-1:\n",
        "        total += \"\\n\"\n",
        "    with open(\"/content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/flask/result.txt\",'w') as file:\n",
        "        file.write(total)\n",
        "    \n",
        "    utils.save_pptx_as_png(\"/content/drive/'Shared drives'/'BigDATA TEAM 10'/dataCampusProject-Team10/flask/outputs\", \"/content/drive/'Shared drives'/'BigDATA TEAM 10'/dataCampusProject-Team10/flask/slides.pptx\", overwrite_folder=True)\n",
        "\n",
        "    with open(os.path.join(basedir, 'result.txt'), 'r', encoding=\"UTF-8\") as file:\n",
        "        string = file.readlines()\n",
        "    with open(os.path.join(basedir, \"relation.txt\"), 'r', encoding=\"UTF-8\") as file:\n",
        "        relation = file.read()\n",
        "    relation = [i for i in relation.split('\\n\\n\\n') if i]\n",
        "    print(relation, len(relation))\n",
        "    print(string, len(string))\n",
        "    with open(os.path.join(basedir, \"templates/result_1.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1 = file.read()\n",
        "    with open(os.path.join(basedir, \"templates/result_1_1.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1_1 = file.read()\n",
        "    with open(os.path.join(basedir, \"templates/result_1_2.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1_2 = file.read()\n",
        "    with open(os.path.join(basedir, \"templates/result_1_3.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1_3 = file.read()\n",
        "    with open(os.path.join(basedir, \"templates/result_1_4.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1_4 = file.read()\n",
        "    with open(os.path.join(basedir, \"templates/result_1_5.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1_5 = file.read()\n",
        "    with open(os.path.join(basedir, \"templates/result_1_6.html\"), \"r\", encoding=\"UTF-8\") as file:\n",
        "        result_1_6 = file.read()\n",
        "    \n",
        "\n",
        "    for j in range(1, len(string)):\n",
        "        result_1 += (\"<a class='nav-link waves-effect' href='#PG\"+ str(j) + \"'><mark><strong>Paragraph \"+ str(j) + \"</strong></mark></a>\")         \n",
        "    result_1 += (\"<a class='nav-link waves-effect' href='#PP'><mark><strong>PowerPoint Slides</strong></mark></a>\")\n",
        "\n",
        "    for i in range(1, len(string)):\n",
        "        result_1 += (\"<div class='col-md-12' id='PG\" + str(i) + \"'><hr><div class='row-eq-height'><div class='col-md-12' style='line-height: 40px'><p class='dark-grey-text'><mark><strong>Paragraph\" + str(i) + \"</strong></mark></p><a style='line-height: 40px'>\")\n",
        "        result_1 += string[i] # paragraph\n",
        "        result_1 += (\"</a><br><div class='col-md-12 text-right'><button type='button' class='btn-yellow' data-toggle='modal' data-target='#PPT\" + str(i) + \"'>PPT</button><button type='button' class='btn-deep-orange' data-toggle='modal' data-target='#P\" + str(i) + \"'>Relation</button></div><div class='modal' id='PPT\" + str(i) + \"'>\")\n",
        "        result_1 += result_1_1\n",
        "        result_1 += (\"<img src='https://raw.githubusercontent.com/yoonkim313/dataCampusProject-Team10/master/5.%20Flask/slide\" + str(i) + \".PNG' class='img-fluid' alt='Sample post image'>\")  # ppt slide picture\n",
        "        result_1 += result_1_2\n",
        "        result_1 += (\"<div class='modal' id='P\" + str(i) + \"'>\")  # relation tagging modal\n",
        "        result_1 += result_1_3\n",
        "        try: result_1 += relation[i-1]\n",
        "        except: pass\n",
        "        result_1 += result_1_4\n",
        "    \n",
        "    result_1 += result_1_5\n",
        "    result_1 += (\"<div class='carousel-item active'><img src='https://raw.githubusercontent.com/yoonkim313/dataCampusProject-Team10/master/5.%20Flask/slide1.PNG' class='d-block w-100' alt='...'></div>\")\n",
        "    \n",
        "    if len(string) > 1:\n",
        "        for i in range(2, len(string)):\n",
        "          result_1 += (\"<div class='carousel-item'><img src='https://raw.githubusercontent.com/yoonkim313/dataCampusProject-Team10/master/5.%20Flask/slide\" + str(i) + \".PNG' class='d-block w-100' alt='...'></div>\")\n",
        "    \n",
        "    result = result_1 + result_1_6\n",
        "\n",
        "    with open(os.path.join(basedir, \"templates/final_result.html\"), \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(result)\n",
        "\n",
        "    return render_template('final_result.html')\n",
        "#################################################################################################################\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/dataCampusProject-Team10/flask\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://f03ec9dd79e4.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [14/Sep/2020 15:43:13] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:14] \"\u001b[37mGET /static/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:14] \"\u001b[37mGET /static/css/mdb.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:14] \"\u001b[37mGET /static/css/style.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:15] \"\u001b[37mGET /static/js/jquery-3.4.1.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:15] \"\u001b[37mGET /static/js/popper.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:15] \"\u001b[37mGET /static/js/bootstrap.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:15] \"\u001b[37mGET /static/js/mdb.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:15] \"\u001b[37mGET /static/img/svg/arrow_right.svg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:15] \"\u001b[37mGET /static/img/svg/arrow_left.svg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:16] \"\u001b[37mGET /static/font/roboto/Roboto-Light.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:16] \"\u001b[37mGET /static/font/roboto/Roboto-Regular.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [14/Sep/2020 15:43:22] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 🧚‍♀️ OCR running 🧚‍♀️ \n",
            "Checked spelling   \n",
            "Checked spelling  암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한 ' 바르 부르크 효과 '에 따르면 암세포는 ' 해당 작용 ' 을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인 ' 산화 적 인산화 '는 억제한다. \n",
            "Checked spelling  세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은 ' 이화 작용 '이라고 한다. 또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을 ' 동화 작용 ' 이라고 한다. 이화 작용을 통해 ATP를 생산하기 위해 세포는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 세포 내부로 이동하여 해당 작용과 산화 적 인산화를 통해 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 에너지 가 전부 ATP로 전환될 경우 36 개 또 \n",
            "Checked spelling  는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다. \n",
            "Checked spelling  \n",
            " 😍  NLP running  😍 \n",
            " Parsed Candidate  [['암세포의', '대사', '과정', '은', '정상', '세포', '와', '다른', '것으로', '알려져', '있다.'], ['_', '_', '과정.n', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'Process', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Process', 'I-Process', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['암세포의', '대사', '과정', '은', '정상', '세포', '와', '다른', '것으로', '알려져', '있다.'], ['_', '_', '_', '_', '정상.n', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', 'Natural_features', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['암세포의', '대사', '과정', '은', '정상', '세포', '와', '다른', '것으로', '알려져', '있다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '알려지다.v', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', 'Awareness', '_'], ['B-Content', 'I-Content', 'I-Content', 'O', 'I-Content', 'I-Content', 'I-Content', 'I-Content', 'I-Content', 'O', 'O']]\n",
            "2    ['B-Process', 'I-Process', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Content', 'I-Content', 'I-Content', 'O', 'I-Content', 'I-Content', 'I-Content', 'I-Content', 'I-Content', 'O', 'O'] -> None\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['오토.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['People_by_origin', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '발표.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', 'Statement', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'O', 'O', 'B-Message', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '효과.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', 'Objective_influence', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '따르다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Attributed_information', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '해당.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Idiosyncrasy', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '에너지.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Electricity', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '획득.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Getting', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Theme', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '수행하다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Intentionally_act', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'B-Act', 'O', 'I-Act', 'O', 'O', 'I-Act', 'I-Act', 'I-Act', 'I-Act', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '획득.n', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Getting', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Recipient', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Theme', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['오토', '바르', '부르크', '가', '발표', '한', \"'\", '바르', '부르크', '효과', \"'에\", '따르면', '암세포는', \"'\", '해당', '작용', \"'\", '을', '주된', '에너지', '획득', '기전으로', '수행하고', '또', '다른', '에너', '지', '획득', '방법인', \"'\", '산화', '적', '인산화', \"'는\", '억제한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '억제하다.v'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Containing'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Contents', 'O', 'O', 'O']]\n",
            "9    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'O', 'O', 'B-Message', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'I-Speaker', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Theme', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'B-Act', 'O', 'I-Act', 'O', 'O', 'I-Act', 'I-Act', 'I-Act', 'I-Act', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Recipient', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Theme', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Contents', 'O', 'O', 'O'] -> None\n",
            " Parsed Candidate  [['세포는', '영양분으로', '섭취', '한', '큰', '분자를', '작은', '분자로', '쪼개는', '과정을', '통해', 'ATP를', '생성하는데', '이', '과정', '은', \"'\", '이화', '작용', \"'이라고\", '한다.'], ['_', '_', '_', '_', '_', '_', '작다.a', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', 'Dimension', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['세포는', '영양분으로', '섭취', '한', '큰', '분자를', '작은', '분자로', '쪼개는', '과정을', '통해', 'ATP를', '생성하는데', '이', '과정', '은', \"'\", '이화', '작용', \"'이라고\", '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '과정.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', 'Process', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['세포는', '영양분으로', '섭취', '한', '큰', '분자를', '작은', '분자로', '쪼개는', '과정을', '통해', 'ATP를', '생성하는데', '이', '과정', '은', \"'\", '이화', '작용', \"'이라고\", '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '통하다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Means', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Agent', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['세포는', '영양분으로', '섭취', '한', '큰', '분자를', '작은', '분자로', '쪼개는', '과정을', '통해', 'ATP를', '생성하는데', '이', '과정', '은', \"'\", '이화', '작용', \"'이라고\", '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '생성.n', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Intentionally_create', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Creator', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Created_entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['세포는', '영양분으로', '섭취', '한', '큰', '분자를', '작은', '분자로', '쪼개는', '과정을', '통해', 'ATP를', '생성하는데', '이', '과정', '은', \"'\", '이화', '작용', \"'이라고\", '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이.n', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Fields', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['세포는', '영양분으로', '섭취', '한', '큰', '분자를', '작은', '분자로', '쪼개는', '과정을', '통해', 'ATP를', '생성하는데', '이', '과정', '은', \"'\", '이화', '작용', \"'이라고\", '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '과정.n', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Process', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "5    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Agent', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Creator', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Created_entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> None\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '같다.a', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', 'Identicality', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '고.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', 'Locale_by_use', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'B-Item', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '에너지.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', 'Electricity', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'B-Source', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '에너지.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', 'Electricity', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '이용.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', 'Using', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'B-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '성장.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Cause_change_of_position_on_a_scale', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '위하다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Purpose', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'B-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'B-Goal', 'I-Goal', 'I-Goal', 'O', 'B-Means', 'I-Means', 'I-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '작다.a', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Dimension', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'I-Object', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '핵.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Weapon', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '같다.a', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Identicality', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Type', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['또한', 'ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '위해', '작은', '분자로부터', '단백질,', '핵', '신과', '같은', '거대', '분자를', '합성하는', '과정을', \"'\", '동화', '작용', \"'\", '이라고', '한다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '과정.n', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Process', '_', '_', '_', '_', '_', '_'], ['O', 'B-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'O', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'O', 'O', 'O', 'I-Process', 'I-Process', 'O', 'O']]\n",
            "10    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'B-Item', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'B-Source', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'B-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'B-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'B-Goal', 'I-Goal', 'I-Goal', 'O', 'B-Means', 'I-Means', 'I-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'I-Object', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Type', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'B-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'O', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'I-Process', 'O', 'O', 'O', 'I-Process', 'I-Process', 'O', 'O'] -> None\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '통하다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'Means', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '생산.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', 'Manufacturing', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'B-Product', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '위하다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', 'Purpose', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Goal', 'I-Goal', 'I-Goal', 'I-Goal', 'I-Goal', 'O', 'B-Means', 'I-Means', 'I-Means', 'I-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '내부.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', 'Part_inner_outer', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-Whole', 'B-Part', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '수송.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', 'Sending', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-Sender', 'B-Theme', 'B-Goal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '내부.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Part_inner_outer', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-Part', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Whole', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이동하다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Cause_motion', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Goal', 'I-Goal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '해당.n', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Idiosyncrasy', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '통하다.v', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Means', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '작다.a', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Dimension', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'I-Object', 'O']]\n",
            " Parsed Candidate  [['이화', '작용을', '통해', 'ATP를', '생산하기', '위해', '세포는', '영양물질을', '내부로', '수송하는데,', '가장', '대표적인', '영양물질인', '포도당', '은', '세포', '내부로', '이동하여', '해당', '작용과', '산화', '적', '인산화를', '통해', '작은', '분', '자로', '분해된다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '분.n', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Measure_duration', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "10    ['B-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'B-Product', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Goal', 'I-Goal', 'I-Goal', 'I-Goal', 'I-Goal', 'O', 'B-Means', 'I-Means', 'I-Means', 'I-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'B-Whole', 'B-Part', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'B-Sender', 'B-Theme', 'B-Goal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'B-Part', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Whole', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Goal', 'I-Goal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Means', 'I-Means', 'I-Means', 'I-Means', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'I-Object', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> None\n",
            " Parsed Candidate  [['이론적으로', '포도당', '1', '개가', '가지고', '있는', '에너지', '가', '전부', 'ATP로', '전환될', '경우', '36', '개', '또'], ['_', '_', '_', '_', '가지다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', 'Possession', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'B-Possession', 'I-Possession', 'I-Possession', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이론적으로', '포도당', '1', '개가', '가지고', '있는', '에너지', '가', '전부', 'ATP로', '전환될', '경우', '36', '개', '또'], ['_', '_', '_', '_', '_', '수_있다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', 'Capability', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'B-Entity', 'I-Entity', 'I-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이론적으로', '포도당', '1', '개가', '가지고', '있는', '에너지', '가', '전부', 'ATP로', '전환될', '경우', '36', '개', '또'], ['_', '_', '_', '_', '_', '_', '에너지.n', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', 'Electricity', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이론적으로', '포도당', '1', '개가', '가지고', '있는', '에너지', '가', '전부', 'ATP로', '전환될', '경우', '36', '개', '또'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '전환.n', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Cause_change', '_', '_', '_', '_'], ['O', 'I-Entity', 'I-Entity', 'I-Entity', 'O', 'O', 'O', 'O', 'B-Final_category', 'I-Final_category', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이론적으로', '포도당', '1', '개가', '가지고', '있는', '에너지', '가', '전부', 'ATP로', '전환될', '경우', '36', '개', '또'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '경우.n', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Instance', '_', '_', '_'], ['O', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'O', 'B-Instance', 'I-Instance', 'I-Instance']]\n",
            " Parsed Candidate  [['이론적으로', '포도당', '1', '개가', '가지고', '있는', '에너지', '가', '전부', 'ATP로', '전환될', '경우', '36', '개', '또'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '개.n', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Obviousness', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "5    ['O', 'B-Possession', 'I-Possession', 'I-Possession', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'B-Entity', 'I-Entity', 'I-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'I-Entity', 'I-Entity', 'I-Entity', 'O', 'O', 'O', 'O', 'B-Final_category', 'I-Final_category', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'I-Instance', 'O', 'B-Instance', 'I-Instance', 'I-Instance'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> None\n",
            " Parsed Candidate  [['는', '38', '개의', 'ATP', '가', '만들어진다.'], ['_', '_', '_', '_', '_', '만들다.v'], ['_', '_', '_', '_', '_', 'Intentionally_create'], ['B-Created_entity', 'B-Created_entity', 'I-Created_entity', 'I-Created_entity', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['이.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['Fields', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '중.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', 'Partitive', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Group', 'O', 'B-Subset', 'I-Subset', 'I-Group', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '_', '_', '_', '_', '_', '일어나다.v', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', 'Event', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'B-Place', 'O', 'B-Event', 'I-Event', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '_', '_', '_', '_', '_', '_', '해당.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', 'Idiosyncrasy', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '통하다.v', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', 'Means', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'B-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '나머지.n', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Rest', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Whole', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '통하다.v', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Means', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'I-Agent', 'O', 'B-Means', 'I-Means', 'I-Means', 'O', 'O']]\n",
            " Parsed Candidate  [['이', '중', '2', '개의', 'ATP는', '세포질에서', '일어나는', '해당', '작용을', '통해,', '나머지는', '미토콘드리아에서', '대부분', '산화', '적', '인산화를', '통해', '만들어진다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '만들다.v'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Cause_change'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Means', 'I-Means', 'I-Means', 'O', 'O']]\n",
            "7    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Group', 'O', 'B-Subset', 'I-Subset', 'I-Group', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'B-Place', 'O', 'B-Event', 'I-Event', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'B-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Whole', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Agent', 'I-Agent', 'O', 'B-Means', 'I-Means', 'I-Means', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Means', 'I-Means', 'I-Means', 'O', 'O'] -> None\n",
            "Relation Extracted\n",
            "['Agent', 'Act', 'Act', 'Act', 'Act', 'Act', 'Act'] ['암세포는', \"'\", '작용', '주된', '에너지', '획득', '기전으로'] Agent\n",
            "['Creator', 'Created_entity'] ['세포는', 'ATP를'] Creator\n",
            "['Means', 'Means', 'Means', 'Means', 'Means', 'Means', 'Means', 'Means', 'Goal', 'Goal', 'Goal', 'Means', 'Means', 'Means'] ['ATP', '와', '같은', '고', '에너지', '분자의', '에너지를', '이용하여', '세포의', '성장과', '분열을', '작은', '분자로부터', '단백질,'] Means\n",
            "['Agent', 'Means', 'Means', 'Means', 'Means'] ['세포는', '작용과', '산화', '적', '인산화를'] Agent\n",
            "['Entity', 'Entity', 'Entity', 'Final_category', 'Final_category'] ['포도당', '1', '개가', '전부', 'ATP로'] Entity\n",
            "['Agent', 'Agent', 'Means', 'Means', 'Means'] ['나머지는', '미토콘드리아에서', '산화', '적', '인산화를'] Agent\n",
            "TEXT\n",
            "Highlight\n",
            "paragraph  [' ', '암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 암세포는   해당 작용   을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 인산화  는 억제한다. ', '세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다. 또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을   동화 작용   이라고 한다. 이화 작용을 통해 ATP를 생산하기 위해 세포는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 세포 내부로 이동하여 해당 작용과 산화 적 인산화를 통해 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 에너지 가 전부 ATP로 전환될 경우 36 개 또 ', '는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다. ']\n",
            "KEYLIST:  ['통해,', '작용을', '작용과', '작용을', 'ATP를', 'ATP', 'ATP를', 'ATP로', 'ATP', 'ATP는', '분자를', '분자로', '분자의', '분자로부터', '분자를', '\\n암세포의', '암세포는', '\\n세포는', '세포의', '세포는', '세포질에서', '에너지', '에너지', '에너지를', '에너지', '인산화', '인산화를', '인산화를', '인산화', '인산화를', '인산화를', '과정을', '과정을']\n",
            " <mark style='background-color:#F9D877'> 단</mark>\n",
            "Highlighted Result   \n",
            "암세포의 대사 <mark style='background-color:#FFD0F2'> 과정</mark> 은 정상 <mark style='background-color:#FFD0F2'> 세포</mark> 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 <mark style='background-color:#FFD0F2'> 암세포</mark>는   해당 <mark style='background-color:#FFD0F2'> 작용</mark>   을 주된 <mark style='background-color:#FFD0F2'> 에너지</mark> 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 <mark style='background-color:#FFD0F2'> 인산</mark>화  는 억제한다. \n",
            "세포는 영양분으로 섭취 한 큰 분자를 작은 <mark style='background-color:#FFD0F2'> 분자</mark>로 쪼개는 <mark style='background-color:#FFD0F2'> 과정을  통해</mark> ATP를 생성하는데 이 <mark style='background-color:#FFD0F2'> 과정</mark> 은   이화 <mark style='background-color:#FFD0F2'> 작용</mark>  이라고 한다. 또한 ATP 와 같은 고 <mark style='background-color:#FFD0F2'> 에너지  분자의  에너지</mark>를 이용하여 <mark style='background-color:#FFD0F2'> 세포</mark>의 성장과 분열을 위해 작은 <mark style='background-color:#FFD0F2'> 분자</mark>로부터 <mark style='background-color:#F9D877'> 단</mark>백질, 핵 신과 같은 거대 <mark style='background-color:#FFD0F2'> 분자</mark>를 합성하는 <mark style='background-color:#FFD0F2'> 과정</mark>을   동화 <mark style='background-color:#FFD0F2'> 작용</mark>   이라고 한다. 이화 <mark style='background-color:#FFD0F2'> 작용을  통해</mark> ATP를 생산하기 위해 <mark style='background-color:#FFD0F2'> 세포</mark>는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 <mark style='background-color:#FFD0F2'> 세포</mark> 내부로 이동하여 해당 <mark style='background-color:#FFD0F2'> 작용</mark>과 산화 적 <mark style='background-color:#FFD0F2'> 인산화를  통해</mark> 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 <mark style='background-color:#FFD0F2'> 에너지</mark> 가 전부 ATP로 전환될 경우 36 개 또 \n",
            "는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 <mark style='background-color:#FFD0F2'> <mark style='background-color:#FFD0F2'> 세포</mark>질</mark>에서 일어나는 해당 <mark style='background-color:#FFD0F2'> 작용을  통해</mark>, 나머지는 미토콘드리아에서 대부분 산화 적 <mark style='background-color:#FFD0F2'> 인산화를  통해</mark> 만들어진다. \n",
            "TEXT\n",
            "Highlight\n",
            "paragraph  [' ', '암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 암세포는   해당 작용   을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 인산화  는 억제한다. ', '세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다. 또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을   동화 작용   이라고 한다. 이화 작용을 통해 ATP를 생산하기 위해 세포는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 세포 내부로 이동하여 해당 작용과 산화 적 인산화를 통해 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 에너지 가 전부 ATP로 전환될 경우 36 개 또 ', '는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다. ']\n",
            "KEYLIST:  ['통해,', '작용을', '작용과', '작용을', 'ATP를', 'ATP', 'ATP를', 'ATP로', 'ATP', 'ATP는', '분자를', '분자로', '분자의', '분자로부터', '분자를', '\\n암세포의', '암세포는', '\\n세포는', '세포의', '세포는', '세포질에서', '에너지', '에너지', '에너지를', '에너지', '인산화', '인산화를', '인산화를', '인산화', '인산화를', '인산화를', '과정을', '과정을']\n",
            "length of paragraphs  4\n",
            "BERT:  ['']\n",
            "Vec  [1]\n",
            "Textrank:  ['']\n",
            "Vec  [1]\n",
            "summarized  \n",
            "TEXT\n",
            "Highlight\n",
            "paragraph  [' ', '암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 암세포는   해당 작용   을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 인산화  는 억제한다. ', '세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다. 또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을   동화 작용   이라고 한다. 이화 작용을 통해 ATP를 생산하기 위해 세포는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 세포 내부로 이동하여 해당 작용과 산화 적 인산화를 통해 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 에너지 가 전부 ATP로 전환될 경우 36 개 또 ', '는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다. ']\n",
            "KEYLIST:  ['통해,', '작용을', '작용과', '작용을', 'ATP를', 'ATP', 'ATP를', 'ATP로', 'ATP', 'ATP는', '분자를', '분자로', '분자의', '분자로부터', '분자를', '\\n암세포의', '암세포는', '\\n세포는', '세포의', '세포는', '세포질에서', '에너지', '에너지', '에너지를', '에너지', '인산화', '인산화를', '인산화를', '인산화', '인산화를', '인산화를', '과정을', '과정을']\n",
            "length of paragraphs  4\n",
            "BERT:  ['암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다 .']\n",
            "Vec  [1, 0]\n",
            "Lexrank:  ['암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다', '오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 암세포는   해당 작용   을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 인산화  는 억제한다']\n",
            "Vec  [1, 1]\n",
            "Textrank:  ['암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다.']\n",
            "Vec  [1, 0]\n",
            "summarized  암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다.\n",
            "TEXT\n",
            "Highlight\n",
            "paragraph  [' ', '암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 암세포는   해당 작용   을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 인산화  는 억제한다. ', '세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다. 또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을   동화 작용   이라고 한다. 이화 작용을 통해 ATP를 생산하기 위해 세포는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 세포 내부로 이동하여 해당 작용과 산화 적 인산화를 통해 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 에너지 가 전부 ATP로 전환될 경우 36 개 또 ', '는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다. ']\n",
            "KEYLIST:  ['통해,', '작용을', '작용과', '작용을', 'ATP를', 'ATP', 'ATP를', 'ATP로', 'ATP', 'ATP는', '분자를', '분자로', '분자의', '분자로부터', '분자를', '\\n암세포의', '암세포는', '\\n세포는', '세포의', '세포는', '세포질에서', '에너지', '에너지', '에너지를', '에너지', '인산화', '인산화를', '인산화를', '인산화', '인산화를', '인산화를', '과정을', '과정을']\n",
            "length of paragraphs  4\n",
            "BERT:  ['세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은 이화 작용 이라고 한다 .']\n",
            "Vec  [1, 0, 1, 0]\n",
            "Lexrank:  ['세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다', '또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을   동화 작용   이라고 한다']\n",
            "Vec  [1, 1, 1, 0]\n",
            "Textrank:  ['세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다.']\n",
            "Vec  [1, 0, 1, 0]\n",
            "summarized  세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다.\n",
            "TEXT\n",
            "Highlight\n",
            "paragraph  [' ', '암세포의 대사 과정 은 정상 세포 와 다른 것으로 알려져 있다. 오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 암세포는   해당 작용   을 주된 에너지 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 인산화  는 억제한다. ', '세포는 영양분으로 섭취 한 큰 분자를 작은 분자로 쪼개는 과정을 통해 ATP를 생성하는데 이 과정 은   이화 작용  이라고 한다. 또한 ATP 와 같은 고 에너지 분자의 에너지를 이용하여 세포의 성장과 분열을 위해 작은 분자로부터 단백질, 핵 신과 같은 거대 분자를 합성하는 과정을   동화 작용   이라고 한다. 이화 작용을 통해 ATP를 생산하기 위해 세포는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 세포 내부로 이동하여 해당 작용과 산화 적 인산화를 통해 작은 분 자로 분해된다. 이론적으로 포도당 1 개가 가지고 있는 에너지 가 전부 ATP로 전환될 경우 36 개 또 ', '는 38 개의 ATP 가 만들어진다. 이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다. ']\n",
            "KEYLIST:  ['통해,', '작용을', '작용과', '작용을', 'ATP를', 'ATP', 'ATP를', 'ATP로', 'ATP', 'ATP는', '분자를', '분자로', '분자의', '분자로부터', '분자를', '\\n암세포의', '암세포는', '\\n세포는', '세포의', '세포는', '세포질에서', '에너지', '에너지', '에너지를', '에너지', '인산화', '인산화를', '인산화를', '인산화', '인산화를', '인산화를', '과정을', '과정을']\n",
            "length of paragraphs  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [14/Sep/2020 15:43:38] \"\u001b[37mGET /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BERT:  ['이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해 , 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다 .']\n",
            "Vec  [0, 1]\n",
            "Lexrank:  ['는 38 개의 ATP 가 만들어진다', '이 중 2 개의 ATP는 세포질에서 일어나는 해당 작용을 통해, 나머지는 미토콘드리아에서 대부분 산화 적 인산화를 통해 만들어진다']\n",
            "Vec  [1, 1]\n",
            "Textrank:  ['는 38 개의 ATP 가 만들어진다.']\n",
            "Vec  [1, 0]\n",
            "summarized  는 38 개의 ATP 가 만들어진다.\n",
            "Comptype module needed to save PNGs.\n",
            "[\"<\\n\\n><a data-toggle='tooltip' data-placement='top' title= Agent▶  Act Act Act Act Act Act> 암세포는▶  ' 작용 주된 에너지 획득 기전으로</a><br><\\n\\n><a data-toggle='tooltip' data-placement='top' title= Creator▶  Created_entity> 세포는▶  ATP를</a><br><a data-toggle='tooltip' data-placement='top' title= Means Means Means Means Means Means Means Means▶  Goal Goal Goal▶  Means Means Means> ATP 와 같은 고 에너지 분자의 에너지를 이용하여▶  세포의 성장과 분열을▶  작은 분자로부터 단백질,</a><br><a data-toggle='tooltip' data-placement='top' title= Agent▶  Means Means Means Means> 세포는▶  작용과 산화 적 인산화를</a><br><a data-toggle='tooltip' data-placement='top' title= Entity Entity Entity▶  Final_category Final_category> 포도당 1 개가▶  전부 ATP로</a><br><\\n\\n><a data-toggle='tooltip' data-placement='top' title= Agent Agent▶  Means Means Means> 나머지는 미토콘드리아에서▶  산화 적 인산화를</a><br><\\n\\n>\"] 1\n",
            "[\"<u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'></u>\\n\", \"<u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'>암세포의 대사 <mark style='background-color:#FFD0F2'> 과정</mark> 은 정상 <mark style='background-color:#FFD0F2'> 세포</mark> 와 다른 것으로 알려져 있다.</u><u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'>오토 바르 부르크 가 발표 한   바르 부르크 효과  에 따르면 <mark style='background-color:#FFD0F2'> 암세포</mark>는   해당 <mark style='background-color:#FFD0F2'> 작용</mark>   을 주된 <mark style='background-color:#FFD0F2'> 에너지</mark> 획득 기전으로 수행하고 또 다른 에너 지 획득 방법인   산화 적 <mark style='background-color:#FFD0F2'> 인산</mark>화  는 억제한다.</u>\\n\", \"<u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'>세포는 영양분으로 섭취 한 큰 분자를 작은 <mark style='background-color:#FFD0F2'> 분자</mark>로 쪼개는 <mark style='background-color:#FFD0F2'> 과정을  통해</mark> ATP를 생성하는데 이 <mark style='background-color:#FFD0F2'> 과정</mark> 은   이화 <mark style='background-color:#FFD0F2'> 작용</mark>  이라고 한다.</u>또한 ATP 와 같은 고 <mark style='background-color:#FFD0F2'> 에너지  분자의  에너지</mark>를 이용하여 <mark style='background-color:#FFD0F2'> 세포</mark>의 성장과 분열을 위해 작은 <mark style='background-color:#FFD0F2'> 분자</mark>로부터 <mark style='background-color:#F9D877'> 단</mark>백질, 핵 신과 같은 거대 <mark style='background-color:#FFD0F2'> 분자</mark>를 합성하는 <mark style='background-color:#FFD0F2'> 과정</mark>을   동화 <mark style='background-color:#FFD0F2'> 작용</mark>   이라고 한다.이화 <mark style='background-color:#FFD0F2'> 작용을  통해</mark> ATP를 생산하기 위해 <mark style='background-color:#FFD0F2'> 세포</mark>는 영양물질을 내부로 수송하는데, 가장 대표적인 영양물질인 포도당 은 <mark style='background-color:#FFD0F2'> 세포</mark> 내부로 이동하여 해당 <mark style='background-color:#FFD0F2'> 작용</mark>과 산화 적 <mark style='background-color:#FFD0F2'> 인산화를  통해</mark> 작은 분 자로 분해된다.이론적으로 포도당 1 개가 가지고 있는 <mark style='background-color:#FFD0F2'> 에너지</mark> 가 전부 ATP로 전환될 경우 36 개 또\\n\", \"<u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'>는 38 개의 ATP 가 만들어진다.</u>이 중 2 개의 ATP는 <mark style='background-color:#FFD0F2'> <mark style='background-color:#FFD0F2'> 세포</mark>질</mark>에서 일어나는 해당 <mark style='background-color:#FFD0F2'> 작용을  통해</mark>, 나머지는 미토콘드리아에서 대부분 산화 적 <mark style='background-color:#FFD0F2'> 인산화를  통해</mark> 만들어진다.\"] 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5hfG55ON92O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
